{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d017482a",
   "metadata": {},
   "source": [
    "## Most Common Packages for Scientific Computing\n",
    "\n",
    "Now that we've taken a look through Python itself we're going to work through some packages of Python code that add functionality to Python. There are an incredible number of packages in Python that do a variety of things. There are packages built for statistics, model fitting, data analysis, big data processing, machine learning, graphical user interface design, plotting, and many more topics. We're going to focus on the basics of two broadly useful packages: numpy and matplotlib.\n",
    "\n",
    "For starters we need to be able to call these packages in order to use their code. This can be done with an `import` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d000825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308bc4f8",
   "metadata": {},
   "source": [
    "While it can be nice to have access to entire packages of code, many programmers tend to only use some packages, or rename them to useful shorthands to make it easier to type multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71511a45",
   "metadata": {},
   "source": [
    "The above is the typical way of including these two packages. One reason it can be useful to keep these names similar between coders is the ability to identify quickly which source package each function comes from in order to access the documentation much quicker. In addition, we typically only need the *pyplot* piece of matplotlib to do simple plotting. If you want to do much fancier, custom plots then you might use additional pieces in the future.\n",
    "\n",
    "Now that we have these packages imported we need to do one final thing in order to make our plots display properly in a Jupyter Notebook. Including something called a *magic commands* (yeah, really) we can make it so matplotlib displays plots inline in our notebook. We're going to use the inline command, but there are many other options found [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9567fdaa",
   "metadata": {},
   "source": [
    "### Loading, Manipulating, and Saving Data\n",
    "\n",
    "As scientists, we want to have easy ways to deal with large amounts of digital data. For some experiments you might find that your handful of data points are easy to plot by hand and do analysis on paper. It is becoming increasingly necessary, however, to be able to hand data with many columns and millions+ of data points. You may eventually even find that numpy might not be able to handle the amount of data you encounter in the future! For now, we're going to use numpy as it will be perfectly capable of handling the amount fo data you'll encounter in most situations. \n",
    "\n",
    "You might wonder why we don't use built-in python data types like lists in order to manipulate our data. You absolutely can! Numpy just makes the process much easier. \n",
    "\n",
    "The most basic case to get data into numpy is to just enter it by hand. We'll be creating a numpy array in order to store our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "data_y = np.array([2,4,6,8,10,12,14,16,18,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9507d18",
   "metadata": {},
   "source": [
    "By entering our data by hand we are essentially giving the `np.array()` function a list and having it convert that into a 1-dimensional array. In physics we typically call this a vector. The great part of numpy is that you can also do math on an array as you would a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3075c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_x*2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04074488",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = data_x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5dee2",
   "metadata": {},
   "source": [
    "But you'll have to be careful if you want to do math with two arrays. Adding, subtracting, multiplying, or dividing does so **by each element**. Looking at our two arrays, dividing data_x by data_y will give every element as 0.5, which is 1/2, 2/4, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c392f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x/data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c563a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x+data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f1976f",
   "metadata": {},
   "source": [
    "So if we want to do specific vector math, like dot or cross-products, we'll need to use functions inside of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.outer(data_x,data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6595629",
   "metadata": {},
   "source": [
    "But these might not be too helpful in data analysis. What will be helpful are functions like sum, average, and mean. Any function that will make our math look a bit less messy, or makes it easier to debug (check and fix) our code. Of course there are also entire statistical packages you can use to do your data analysis for you, but you still need to understand the math done behind them in order to interpret your data. This means before you use useful functions like polyfit, you should understand *how* it determines the best fitting polynomial, or how the math from each function is useful to interpreting your data in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86825d37",
   "metadata": {},
   "source": [
    "Another important feature of arrays is indexing or slicing. This gives us a quick way to filter data according to whatever criteria we can think of. This is done a few ways. We can specify the index of a particular data point if we know what we want. We can also take a slice of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36830945",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x[5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c563d5ce",
   "metadata": {},
   "source": [
    "The above starts at position 5 in the array and ends at position 8 (exclusive). Just like lists and other multi-element data types in Python, indexing starts with zero.\n",
    "\n",
    "We can also give conditions if we know what data we want, but not where it is in the array. This is done with conditional statements, using >, >=, ==, <, <=, and !=. These were covered in the Python tutorial, but for clarity the two odd looking conditionals are == (equals) and != (not equal). We use a double equals because the single equal sign is used for assigning values to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577dd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x[data_x!= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x[data_x>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y[data_x<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa05e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y[data_x>=5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c53af1",
   "metadata": {},
   "source": [
    "So we can do a bit of math on our data, and we can input by hand, but maybe our data is fairly large. We need to be able to read a datafile in, do some analysis, and save it to work on later. The first step in this is to have some data to read in. For this we'll use `test_read.txt`. This is just some generic data I made in order to demonstrate this functionality. The command we'll use to read files in will be `np.loadtxt` which will load a text file that you specify. There are also a large amount of options in this [function](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html#numpy.loadtxt), so this might look daunting at first. Let's just try to open the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('test_read.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34552e93",
   "metadata": {},
   "source": [
    "We can see that our file has trouble loading with this function. It looks like it doesn't like the % symbol that denotes our header. We can do a number of things to get around this. The simplest thing to do is to use the `skiprows` argument in our function. This tell loadtxt to skip the first n rows that you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('test_read.txt', skiprows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465961a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a327085",
   "metadata": {},
   "source": [
    "We could also specify the % symbol as denoting a comment, but this argument is more broadly useful. We also note that our data loads into a single, 2-dimensional array. If we'd rather split it so that each column is its own array, we can do that as well with `unpack=True`. If we had a large number of columns and knew we only wanted some of them we can use `usecols=(tuple)` to pick only the columns we want, starting with the first as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = np.loadtxt('test_read.txt', skiprows = 4, usecols=(0,1), unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b927b9",
   "metadata": {},
   "source": [
    "Finally, two separate arrays. Of course, now that we have these two separate arrays we can finally work on plotting data. The simplest way to plot in pyplot is simply the `plot` function. In order to plot we first need to create a figure to plot onto through `plt.figure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(data_x, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1bc51",
   "metadata": {},
   "source": [
    "We did it, that's it, that's a plot. But it's not a good plot. At this point we don't know what's plotted, nothing is labeled, and all of the data points are connected together, which may not be what we want. Again, pyplot has many options and extra ways of plotting [matplotlib.pyplot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html) so we'll focus on the simplest and most universal.\n",
    "\n",
    "Most important for plotting is telling the eventual reader (or grader) what you've plotted. This is really easy. The functions `plt.title, plt.xlabel, and plt.ylabel` are exactly what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(data_x, data_y)\n",
    "plt.title('data_y vs. data_x for Demo Purposes')\n",
    "plt.xlabel('data_x (units)')\n",
    "plt.ylabel('data_y (units)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d98931",
   "metadata": {},
   "source": [
    "Better, but we can do even more. If you look at [this](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot) we can see there are a lot of options to customize. Since this might be an intimidating list, let's focus on linestyle, marker, label, and color.\n",
    "\n",
    "Linestyle can be written as an argument `linestyle='style'` or even `ls='style`. To get data points we use `ls='none'`. This leads us to the marker style. This can be set with `marker='style'`, using the various choices [here](https://matplotlib.org/stable/api/markers_api.html#module-matplotlib.markers). I suggest using `marker='.'` to get simple datapoints. Label is useful for us if we have multiple datasets to plot on the same axis. You only need to give it a string of text that will be displayed if you make a legend. Finally, color is the option to change the color of whatever you're plotting. You can give it the name of a color from [here](https://matplotlib.org/stable/api/colors_api.html#module-matplotlib.colors), or a hexidecimal color code from [here](https://www.w3schools.com/colors/colors_picker.asp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(data_x, data_y, ls='none', marker='.', color='#29a329', label='Dataset 1')\n",
    "plt.title('data_y vs. data_x for Demo Purposes')\n",
    "plt.xlabel('data_x (units)')\n",
    "plt.ylabel('data_y (units)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f1d25",
   "metadata": {},
   "source": [
    "Now we have our data plotted, things are starting to look nice, but it would be nice to have a bigger plot. This is accomplished with the `figsize=(x,y)` option in `plt.figure()`. The size in x and y is specified in inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771edc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8))\n",
    "plt.plot(data_x, data_y, ls='none', marker='.', color='#29a329', label='Dataset 1')\n",
    "plt.title('data_y vs. data_x for Demo Purposes')\n",
    "plt.xlabel('data_x (units)')\n",
    "plt.ylabel('data_y (units)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76736c9f",
   "metadata": {},
   "source": [
    "Let's explore the possibility of multiple datasets. First, let's create an dataset out of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5360353",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 10*x**3+100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013d75f",
   "metadata": {},
   "source": [
    "So we've created a quick function to plot using `np.arange()` which takes, in order, the starting value, ending value, and step size. Then we created a function $y=10x^3+100$. So, let's plot both on the same plot and make use of `plt.legend()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8))\n",
    "plt.plot(data_x, data_y, ls='none', marker='.', color='#29a329', label='Dataset 1')\n",
    "plt.plot(x, y, ls='none', marker='.', color='blue', label='Dataset 2')\n",
    "plt.title('data_y vs. data_x for Demo Purposes')\n",
    "plt.xlabel('data_x (units)')\n",
    "plt.ylabel('data_y (units)')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39cc1b",
   "metadata": {},
   "source": [
    "Alright, we've done quite a bit of work here. Let's save our new function out into a text file. This can be done with `np.savetxt()`, but we'll need to stack our data into a single array. To do this, we'll use `np.stack()` and stack along `axis=1` to keep them as two columns for ease of access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedata = np.stack((x,y), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cfbf55",
   "metadata": {},
   "source": [
    "And now all this is left is to save our data. Just like with the data we read in we can create a header to save useful context along with our file. This is simply a string, but I like to use the triple quotes way to create a multi-line string. If you go further in programming more fundamentally, this is called a docstring and is typically used to document what your created functions, programs, and packages do. For us, it will be a useful way of formatting a header for our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"\"\"Here is a test file that we created to practice with numpy.\n",
    "x(units)   y(units)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_out.txt', savedata, header=header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f649c1a",
   "metadata": {},
   "source": [
    "And so finally we have saved our file as 'test_out.txt', saved the variable `savedata` as our data to be saved into the file, and have given it a header which is saved in our `header` variable. You could also save the filename as it's own string as well. There are other options you can see [here](https://numpy.org/doc/stable/reference/generated/numpy.savetxt.html), but these few will be the most broadly useful to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1f08f",
   "metadata": {},
   "source": [
    "Remember when we sliced/indexed our arrays above? Well, let's do that with our large array. Let's say we only want to plot our data when data_y is positive. We could use `plt.ylim(lower limit, upper limit)` to chop our graph off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ee814",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8))\n",
    "plt.plot(data_x, data_y, ls='none', marker='.', color='#29a329', label='Dataset 1')\n",
    "plt.plot(x, y, ls='none', marker='.', color='blue', label='Dataset 2')\n",
    "plt.title('data_y vs. data_x for Demo Purposes')\n",
    "plt.xlabel('data_x (units)')\n",
    "plt.ylabel('data_y (units)')\n",
    "plt.ylim(0, )\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227c469",
   "metadata": {},
   "source": [
    "But this doesn't account for the x axis. We could go back and set our `plt.xlim()`, OR we could slice the arrays directly. Let's take our data where data_y > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8))\n",
    "plt.plot(data_x[data_y>0], data_y[data_y>0], ls='none', marker='.', color='#29a329', label='Dataset 1')\n",
    "plt.plot(x[y>0], y[y>0], ls='none', marker='.', color='blue', label='Dataset 2')\n",
    "plt.title('data_y vs. data_x for Demo Purposes')\n",
    "plt.xlabel('data_x (units)')\n",
    "plt.ylabel('data_y (units)')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f2e7ad",
   "metadata": {},
   "source": [
    "This gives us a bit of a cleaner view of our data, without cutting points off with the axis or having to worry about setting the x and y limits for the plot. There will be cases where you might want to index vs. setting plot limits or vice versa. It's up to you to decide which is the better/easier/preferred way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe999a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
